#!/usr/bin/env python3
"""
AIå·¥å…·æ¨èæŠ“å–è„šæœ¬ - æœ€æ–°ç‰ˆæœ¬
ä¸“é—¨ä¸ºç¯å¢ƒç§‘å­¦ã€GISå’Œæ•°æ®åˆ†æèƒŒæ™¯çš„å­¦ç”Ÿå®šåˆ¶çš„å·¥å…·æ¨è
"""

import requests
import json
import datetime
import time
import random
import os

class AIToolsScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/vnd.github.v3+json'
        })
        self.tools_data = []

    def scrape_github_environmental_projects(self):
        """æŠ“å–GitHubç¯å¢ƒç§‘å­¦ç›¸å…³çƒ­é—¨é¡¹ç›®"""
        try:
            # æœç´¢ç¯å¢ƒç§‘å­¦ç›¸å…³çš„çƒ­é—¨é¡¹ç›®
            keywords = ['environmental-data', 'climate-analysis', 'gis-tools', 'earth-observation']

            for keyword in keywords[:2]:  # é™åˆ¶APIè°ƒç”¨
                url = "https://api.github.com/search/repositories"
                params = {
                    'q': f'{keyword} language:python stars:>100',
                    'sort': 'updated',
                    'per_page': 2
                }

                try:
                    response = self.session.get(url, params=params, timeout=10)
                    if response.status_code == 200:
                        data = response.json()

                        for repo in data.get('items', [])[:1]:
                            if repo.get('description'):
                                self.tools_data.append({
                                    'name': repo['name'],
                                    'summary': self.truncate_text(repo['description'], 80),
                                    'usefulness': f"è¿™ä¸ª{keyword}ç›¸å…³çš„Pythoné¡¹ç›®ç‰¹åˆ«é€‚ç”¨äºç¯å¢ƒæ•°æ®åˆ†æå’Œåœ°ç†ç©ºé—´å¤„ç†ä»»åŠ¡ã€‚å¯¹äºç¯å¢ƒç§‘å­¦å­¦ç”Ÿæ¥è¯´ï¼Œå®ƒæä¾›äº†å®é™…çš„å·¥å…·å’Œæ–¹æ³•æ¥å¤„ç†å¤æ‚çš„ç¯å¢ƒæ•°æ®é›†ã€‚",
                                    'technical': f"åŸºäºPythonå¼€å‘ï¼Œåœ¨GitHubä¸Šæœ‰{repo['stargazers_count']}ä¸ªæ˜Ÿæ ‡ã€‚å¯é€šè¿‡pipå®‰è£…ï¼Œä¸pandasã€numpyã€matplotlibç­‰ç§‘å­¦è®¡ç®—åº“æ— ç¼é›†æˆã€‚æ”¯æŒJupyter Notebookç¯å¢ƒã€‚",
                                    'category': 'programming',
                                    'difficulty': 'ä¸­çº§',
                                    'link': repo['html_url'],
                                    'stars': repo['stargazers_count']
                                })

                    time.sleep(1)  # APIè°ƒç”¨é—´éš”

                except Exception as api_error:
                    print(f"GitHub API error for {keyword}: {api_error}")

            print(f"GitHub projects: æ”¶é›† {len([t for t in self.tools_data if 'github.com' in t.get('link', '')])} ä¸ªçƒ­é—¨é¡¹ç›®")

        except Exception as e:
            print(f"GitHub scraping error: {e}")

    def truncate_text(self, text, max_length):
        """æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šé•¿åº¦"""
        if len(text) <= max_length:
            return text
        return text[:max_length] + "..."

    def add_essential_gis_tools(self):
        """æ·»åŠ æ ¸å¿ƒGISå’Œç¯å¢ƒç§‘å­¦å·¥å…·"""
        essential_tools = [
            {
                'name': 'QGIS',
                'summary': 'ä¸–ç•Œé¢†å…ˆçš„å¼€æºåœ°ç†ä¿¡æ¯ç³»ç»Ÿï¼Œæ”¯æŒå…¨æ–¹ä½ç©ºé—´æ•°æ®åˆ†æ',
                'usefulness': 'å¯¹ç¯å¢ƒç§‘å­¦å­¦ç”Ÿæ¥è¯´æ˜¯å¿…å¤‡æŠ€èƒ½ã€‚QGISå®Œå…¨å…è´¹ï¼ŒåŠŸèƒ½åª²ç¾æ˜‚è´µçš„ArcGISã€‚æ”¯æŒ200+ç§æ•°æ®æ ¼å¼ï¼Œä»ç®€å•åœ°å›¾åˆ¶ä½œåˆ°å¤æ‚ç©ºé—´åˆ†æéƒ½èƒ½èƒœä»»ã€‚å­¦ä¼šQGISåå¯è½»æ¾è½¬æ¢åˆ°ä»»ä½•GISå¹³å°ï¼Œæ˜¯æ±‚èŒå’Œå­¦æœ¯ç ”ç©¶çš„é‡è¦åŠ åˆ†é¡¹ã€‚',
                'technical': 'åŸºäºC++å’ŒQtæ¡†æ¶ï¼Œè·¨å¹³å°æ”¯æŒWindows/Mac/Linuxã€‚å†…ç½®Pythonæ§åˆ¶å°æ”¯æŒè‡ªåŠ¨åŒ–è„šæœ¬ï¼Œæ‹¥æœ‰500+æ’ä»¶æ‰©å±•åŠŸèƒ½ã€‚æ”¯æŒOGCæ ‡å‡†ï¼Œå¯ä¸Rã€Pythonã€PostGISæ— ç¼é›†æˆè¿›è¡Œé«˜çº§åˆ†æã€‚',
                'category': 'GIS',
                'difficulty': 'åˆçº§',
                'link': 'https://qgis.org/',
                'stars': 'N/A'
            },
            {
                'name': 'Google Earth Engine',
                'summary': 'è°·æ­Œäº‘ç«¯è¡Œæ˜Ÿçº§åœ°ç†ç©ºé—´åˆ†æå¹³å°ï¼Œé›†æˆPBçº§å«æ˜Ÿæ•°æ®',
                'usefulness': 'é©å‘½æ€§çš„äº‘ç«¯GISå¹³å°ï¼Œæ— éœ€ä¸‹è½½TBçº§æ•°æ®å³å¯è¿›è¡Œå…¨çƒåˆ†æã€‚ç‰¹åˆ«é€‚ç”¨äºæ°”å€™å˜åŒ–ç›‘æµ‹ã€æ£®æ—ç ä¼è¿½è¸ªã€åŸå¸‚æ‰©å¼ ç ”ç©¶ã€å†œä¸šç›‘æµ‹ç­‰å¤§å°ºåº¦ç¯å¢ƒç ”ç©¶ã€‚å¯¹å‘è¡¨é«˜å½±å“å› å­ç¯å¢ƒç§‘å­¦è®ºæ–‡æå…¶æœ‰ç”¨ã€‚',
                'technical': 'é€šè¿‡JavaScriptå’ŒPython APIè®¿é—®ï¼Œé›†æˆLandsatã€Sentinelã€MODISã€CHIRPSç­‰å‡ åä¸ªæƒå¨æ•°æ®é›†ã€‚è®¡ç®—åœ¨Googleäº‘ç«¯è¿›è¡Œï¼Œæ”¯æŒæœºå™¨å­¦ä¹ ç®—æ³•ã€‚æä¾›äº¤äº’å¼ä»£ç ç¼–è¾‘å™¨ï¼Œå¯å¯¼å‡ºé«˜åˆ†è¾¨ç‡ç»“æœã€‚',
                'category': 'GIS',
                'difficulty': 'ä¸­çº§',
                'link': 'https://earthengine.google.com/',
                'stars': 'N/A'
            },
            {
                'name': 'Pythonåœ°ç†ç©ºé—´ç”Ÿæ€ç³»ç»Ÿ',
                'summary': 'GeoPandas + Rasterio + Folium + Cartopyå®Œæ•´å·¥å…·é“¾',
                'usefulness': 'Pythonåœ¨ç¯å¢ƒæ•°æ®ç§‘å­¦ä¸­åœ°ä½æ— å¯æ›¿ä»£ã€‚GeoPandasè®©ç©ºé—´æ•°æ®å¤„ç†å¦‚Excelèˆ¬ç®€å•ï¼ŒFoliumåˆ›å»ºäº¤äº’å¼Webåœ°å›¾ï¼ŒRasterioå¤„ç†å«æ˜Ÿå½±åƒï¼ŒCartopyåˆ¶ä½œç§‘å­¦åœ°å›¾ã€‚è¦†ç›–ä»æ•°æ®è·å–åˆ°å¯è§†åŒ–çš„å®Œæ•´æµç¨‹ã€‚',
                'technical': 'æ ¸å¿ƒåº“åŒ…æ‹¬GeoPandas(ç©ºé—´DataFrame)ã€Rasterio(æ …æ ¼I/O)ã€Shapely(å‡ ä½•è¿ç®—)ã€Folium(äº¤äº’åœ°å›¾)ã€Cartopy(åœ°å›¾æŠ•å½±)ã€PyProj(åæ ‡è½¬æ¢)ã€‚ä¸Jupyterã€Pandasã€NumPyã€Matplotlibå®Œç¾é›†æˆã€‚',
                'category': 'ç¼–ç¨‹',
                'difficulty': 'ä¸­çº§',
                'link': 'https://geopandas.org/',
                'stars': 'N/A'
            },
            {
                'name': 'R Spatialç”Ÿæ€ç³»ç»Ÿ',
                'summary': 'sf + terra + tmap + rgeeç­‰Rè¯­è¨€ç©ºé—´åˆ†æåŒ…',
                'usefulness': 'Råœ¨ç»Ÿè®¡ç”Ÿæ€å­¦å’Œç¯å¢ƒå»ºæ¨¡ä¸­ä¼˜åŠ¿æ˜¾è‘—ã€‚sfåŒ…æä¾›ç°ä»£ç©ºé—´æ•°æ®å¤„ç†ï¼Œterraå¤„ç†å¤§å‹æ …æ ¼ï¼Œtmapåˆ›å»ºå‡ºç‰ˆçº§åœ°å›¾ï¼Œrgeeè¿æ¥Google Earth Engineã€‚ç‰¹åˆ«é€‚åˆç‰©ç§åˆ†å¸ƒå»ºæ¨¡ã€ç”Ÿæ€ç»Ÿè®¡ã€ç¯å¢ƒç›‘æµ‹åˆ†æã€‚',
                'technical': 'åŸºäºsfæ ‡å‡†çš„ç°ä»£ç©ºé—´æ¡†æ¶ï¼Œä¸tidyverseç”Ÿæ€æ— ç¼é›†æˆã€‚æ”¯æŒå¤æ‚ç»Ÿè®¡æ¨¡å‹å¦‚GAMã€æ··åˆæ•ˆåº”æ¨¡å‹ã€‚é€šè¿‡rgeeç›´æ¥è®¿é—®Google Earth Engineï¼Œå®ç°Rä¸äº‘ç«¯GISç»“åˆã€‚æ‹¥æœ‰3000+ä¸“ä¸šåŒ…ã€‚',
                'category': 'ç¼–ç¨‹',
                'difficulty': 'ä¸­é«˜çº§',
                'link': 'https://r-spatial.github.io/sf/',
                'stars': 'N/A'
            },
            {
                'name': 'GRASS GIS',
                'summary': 'åŠŸèƒ½å¼ºå¤§çš„å¼€æºGISå’Œé¥æ„Ÿåˆ†æç³»ç»Ÿ',
                'usefulness': 'ç‰¹åˆ«æ“…é•¿æ …æ ¼æ•°æ®åˆ†æå’Œåœ°å½¢å»ºæ¨¡ï¼Œæ˜¯ç§‘å­¦ç ”ç©¶çš„åˆ©å™¨ã€‚å†…ç½®500+åˆ†æå·¥å…·ï¼Œæ”¯æŒé«˜çº§æ°´æ–‡å»ºæ¨¡ã€æ™¯è§‚ç”Ÿæ€å­¦åˆ†æã€é¥æ„Ÿå›¾åƒå¤„ç†ã€‚åœ¨å­¦æœ¯ç•Œäº«æœ‰å¾ˆé«˜å£°èª‰ï¼Œå¾ˆå¤šç®—æ³•çš„æ ‡å‡†å®ç°ã€‚',
                'technical': 'ç”¨Cè¯­è¨€å¼€å‘ï¼Œæ‰§è¡Œæ•ˆç‡æé«˜ã€‚å¯é€šè¿‡Pythonã€Ræ¥å£è°ƒç”¨ã€‚æ”¯æŒå¹¶è¡Œå¤„ç†å¤§æ•°æ®é›†ã€‚æ‹¥æœ‰30å¹´æŒç»­å¼€å‘å†å²ï¼Œç®—æ³•ç»è¿‡å……åˆ†éªŒè¯ã€‚å¯ä¸QGISé›†æˆä½¿ç”¨ã€‚',
                'category': 'GIS',
                'difficulty': 'é«˜çº§',
                'link': 'https://grass.osgeo.org/',
                'stars': 'N/A'
            }
        ]

        # éšæœºé€‰æ‹©3-4ä¸ªå·¥å…·ä»¥ä¿æŒæ–°é²œæ„Ÿ
        selected_tools = random.sample(essential_tools, min(4, len(essential_tools)))
        self.tools_data.extend(selected_tools)
        print(f"Essential tools: æ·»åŠ  {len(selected_tools)} ä¸ªæ ¸å¿ƒå·¥å…·")

    def scrape_all_sources(self):
        """æ‰§è¡Œæ‰€æœ‰æ”¶é›†ä»»åŠ¡"""
        print("ğŸ¤– å¼€å§‹æ”¶é›†AIå·¥å…·æ¨è...")

        # å…ˆæ·»åŠ æ ¸å¿ƒå·¥å…·
        self.add_essential_gis_tools()

        # å°è¯•è·å–GitHubçƒ­é—¨é¡¹ç›®
        self.scrape_github_environmental_projects()

        # éšæœºæ’åºä¿æŒæ–°é²œæ„Ÿ
        random.shuffle(self.tools_data)

        print(f"âœ… æˆåŠŸæ”¶é›† {len(self.tools_data)} ä¸ªå·¥å…·æ¨è")
        return self.tools_data

    def save_to_json(self, filename="data/ai_tools.json"):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'last_updated': datetime.datetime.now().isoformat(),
                'tools': self.tools_data
            }, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ° {filename}")

if __name__ == "__main__":
    scraper = AIToolsScraper()
    scraper.scrape_all_sources()
    scraper.save_to_json()
