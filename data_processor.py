#!/usr/bin/env python3
"""
æ•°æ®å¤„ç†å’Œæ•´åˆè„šæœ¬ - æœ€æ–°ç‰ˆæœ¬
æ•´åˆæ‰€æœ‰æŠ“å–çš„æ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—ã€åŽ»é‡ã€ä¼˜å…ˆçº§æŽ’åºï¼Œç”Ÿæˆæœ€ç»ˆçš„ä»ªè¡¨ç›˜æ•°æ®
"""

import json
import datetime
import os
from pathlib import Path

class DashboardDataProcessor:
    def __init__(self):
        self.data_dir = Path("data")
        self.final_data = {
            'last_updated': datetime.datetime.now().isoformat(),
            'current_date': datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥'),
            'environmental_news': [],
            'ai_tools': [],
            'opportunities': []
        }

    def load_json_file(self, filename):
        """å®‰å…¨åŠ è½½JSONæ–‡ä»¶"""
        filepath = self.data_dir / filename
        if filepath.exists():
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ {filename} æ—¶å‡ºé”™: {e}")
                return None
        else:
            print(f"ðŸ“‚ æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
            return None

    def process_environmental_news(self):
        """å¤„ç†çŽ¯å¢ƒç§‘å­¦æ–°é—»æ•°æ®"""
        news_data = self.load_json_file("environmental_news.json")
        if news_data and 'news' in news_data:
            news_items = news_data['news']

            # æŒ‰ç´§æ€¥ç¨‹åº¦å’Œæ—¶æ•ˆæ€§æŽ’åº
            def sort_key(item):
                urgency_priority = {'high': 0, 'medium': 1, 'low': 2}
                category_priority = {'climate': 0, 'academic': 1, 'policy': 2}
                return (
                    urgency_priority.get(item.get('urgency', 'medium'), 1),
                    category_priority.get(item.get('category', 'academic'), 1),
                    item.get('date', ''),
                    item.get('title', '')
                )

            news_items.sort(key=sort_key, reverse=True)

            # é™åˆ¶æ•°é‡å¹¶ç¡®ä¿å†…å®¹è´¨é‡
            processed_news = []
            for item in news_items[:6]:  # æœ€å¤š6æ¡æ–°é—»
                if item.get('title') and len(item['title']) > 10:
                    processed_news.append(item)

            self.final_data['environmental_news'] = processed_news
            print(f"ðŸ“° å¤„ç†äº† {len(processed_news)} æ¡çŽ¯å¢ƒç§‘å­¦æ–°é—»")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°çŽ¯å¢ƒæ–°é—»æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹")
            self.add_fallback_news()

    def add_fallback_news(self):
        """æ·»åŠ å¤‡ç”¨æ–°é—»å†…å®¹"""
        fallback_news = [
            {
                'title': 'çŽ¯å¢ƒç§‘å­¦æ•°æ®æ”¶é›†å®Œæˆ',
                'description': 'ç³»ç»Ÿå·²æˆåŠŸåˆå§‹åŒ–ï¼Œå¼€å§‹æ”¶é›†æœ€æ–°çš„çŽ¯å¢ƒç§‘å­¦åŠ¨æ€ã€‚è¯·ç­‰å¾…ä¸‹æ¬¡è‡ªåŠ¨æ›´æ–°ä»¥èŽ·å–å®žæ—¶æ–°é—»å†…å®¹ã€‚',
                'source': 'ç³»ç»Ÿé€šçŸ¥',
                'date': datetime.datetime.now().strftime('%Y-%m-%d'),
                'category': 'system',
                'urgency': 'medium',
                'link': '#'
            }
        ]
        self.final_data['environmental_news'] = fallback_news

    def process_ai_tools(self):
        """å¤„ç†AIå·¥å…·æŽ¨èæ•°æ®"""
        tools_data = self.load_json_file("ai_tools.json")
        if tools_data and 'tools' in tools_data:
            tools_items = tools_data['tools']

            # æŒ‰ç±»åˆ«å’Œå®žç”¨æ€§æŽ’åº
            def sort_key(item):
                category_priority = {'GIS': 0, 'ç¼–ç¨‹': 1, 'programming': 1, 'é…ç½®': 2}
                difficulty_priority = {'åˆçº§': 0, 'ä¸­çº§': 1, 'ä¸­é«˜çº§': 2, 'é«˜çº§': 3}
                return (
                    category_priority.get(item.get('category', 'programming'), 1),
                    difficulty_priority.get(item.get('difficulty', 'ä¸­çº§'), 1),
                    item.get('name', '')
                )

            tools_items.sort(key=sort_key)

            # ç¡®ä¿å·¥å…·å¤šæ ·æ€§
            processed_tools = []
            categories_seen = set()

            for item in tools_items:
                if len(processed_tools) >= 5:  # æœ€å¤š5ä¸ªå·¥å…·
                    break

                category = item.get('category', 'other')
                if len(processed_tools) < 3 or category not in categories_seen:
                    processed_tools.append(item)
                    categories_seen.add(category)

            self.final_data['ai_tools'] = processed_tools
            print(f"ðŸ¤– å¤„ç†äº† {len(processed_tools)} ä¸ªAIå·¥å…·æŽ¨è")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°å·¥å…·æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹")
            self.add_fallback_tools()

    def add_fallback_tools(self):
        """æ·»åŠ å¤‡ç”¨å·¥å…·å†…å®¹"""
        fallback_tools = [
            {
                'name': 'å·¥å…·æŽ¨èç³»ç»Ÿåˆå§‹åŒ–',
                'summary': 'æ­£åœ¨æ”¶é›†æœ€æ–°çš„AIå’ŒGISå·¥å…·æŽ¨è',
                'usefulness': 'ç³»ç»Ÿæ­£åœ¨ä¸ºæ‚¨æ”¶é›†æœ€é€‚åˆçŽ¯å¢ƒç§‘å­¦å­¦ä¹ å’Œç ”ç©¶çš„å·¥å…·æŽ¨èã€‚',
                'technical': 'ä¸‹æ¬¡æ›´æ–°å°†åŒ…å«QGISã€Google Earth Engineã€Pythonå·¥å…·ç­‰æŽ¨èã€‚',
                'category': 'ç³»ç»Ÿ',
                'difficulty': 'æ— ',
                'link': '#'
            }
        ]
        self.final_data['ai_tools'] = fallback_tools

    def process_opportunities(self):
        """å¤„ç†å®žè·µæœºä¼šæ•°æ®"""
        opp_data = self.load_json_file("opportunities.json")
        if opp_data and 'opportunities' in opp_data:
            opp_items = opp_data['opportunities']

            # æŒ‰ç±»åž‹å’Œåœ°ç†ä½ç½®ä¼˜å…ˆçº§æŽ’åº
            def sort_key(item):
                type_priority = {'å¿—æ„¿è€…': 0, 'å…¼èŒç ”ç©¶': 1, 'å…¨èŒå°±ä¸š': 2, 'é…ç½®æç¤º': 3}
                location_priority = 0 if 'ACT' in item.get('location', '') else 1
                return (
                    type_priority.get(item.get('type', 'å…¶ä»–'), 2),
                    location_priority,
                    item.get('title', '')
                )

            opp_items.sort(key=sort_key)

            # ç¡®ä¿æœºä¼šç±»åž‹å¤šæ ·æ€§
            processed_opportunities = []
            types_seen = set()

            for item in opp_items:
                if len(processed_opportunities) >= 6:  # æœ€å¤š6ä¸ªæœºä¼š
                    break

                opp_type = item.get('type', 'other')
                if len(processed_opportunities) < 3 or opp_type not in types_seen:
                    processed_opportunities.append(item)
                    types_seen.add(opp_type)

            self.final_data['opportunities'] = processed_opportunities
            print(f"ðŸ’¼ å¤„ç†äº† {len(processed_opportunities)} ä¸ªå®žè·µæœºä¼š")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°æœºä¼šæ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹")
            self.add_fallback_opportunities()

    def add_fallback_opportunities(self):
        """æ·»åŠ å¤‡ç”¨æœºä¼šå†…å®¹"""
        fallback_opportunities = [
            {
                'title': 'å®žè·µæœºä¼šæ”¶é›†ä¸­',
                'description': 'ç³»ç»Ÿæ­£åœ¨æ”¶é›†å ªåŸ¹æ‹‰åœ°åŒºæœ€æ–°çš„çŽ¯å¢ƒç›¸å…³å¿—æ„¿è€…å’Œå°±ä¸šæœºä¼šã€‚',
                'organization': 'ç³»ç»Ÿé€šçŸ¥',
                'location': 'å ªåŸ¹æ‹‰ACT',
                'type': 'ç³»ç»Ÿæ¶ˆæ¯',
                'commitment': 'è¯·ç­‰å¾…æ›´æ–°',
                'skills': 'æ— éœ€ç‰¹æ®ŠæŠ€èƒ½',
                'contact': 'ç³»ç»Ÿè‡ªåŠ¨æ›´æ–°',
                'link': '#'
            }
        ]
        self.final_data['opportunities'] = fallback_opportunities

    def add_metadata(self):
        """æ·»åŠ å…ƒæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯"""
        total_items = (
            len(self.final_data['environmental_news']) + 
            len(self.final_data['ai_tools']) + 
            len(self.final_data['opportunities'])
        )

        current_time = datetime.datetime.now()
        next_update = current_time + datetime.timedelta(days=1)

        self.final_data['metadata'] = {
            'total_items': total_items,
            'last_processing_time': current_time.strftime('%Y-%m-%d %H:%M:%S AEST'),
            'next_update': next_update.strftime('%Y-%m-%d %H:%M:%S AEST'),
            'data_sources': [
                'ANU Fenner School',
                'Australian Climate Council', 
                'GitHub Trending',
                'ACT Government',
                'Conservation Organizations',
                'Environmental Consulting Firms'
            ],
            'categories': {
                'news': len(self.final_data['environmental_news']),
                'tools': len(self.final_data['ai_tools']),
                'opportunities': len(self.final_data['opportunities'])
            }
        }

    def process_all_data(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹"""
        print("ðŸ“Š å¼€å§‹æ•°æ®å¤„ç†å’Œæ•´åˆ...")

        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.data_dir.mkdir(exist_ok=True)

        # å¤„ç†å„ç±»æ•°æ®
        self.process_environmental_news()
        self.process_ai_tools()
        self.process_opportunities()
        self.add_metadata()

        # ä¿å­˜æœ€ç»ˆæ•´åˆæ•°æ®
        output_file = self.data_dir / "dashboard_data.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.final_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼æœ€ç»ˆæ•°æ®ä¿å­˜åˆ° {output_file}")
        print(f"ðŸ“ˆ æ€»å…±å¤„ç†äº† {self.final_data['metadata']['total_items']} æ¡è®°å½•")
        print(f"   ðŸ“° æ–°é—»: {self.final_data['metadata']['categories']['news']} æ¡")
        print(f"   ðŸ¤– å·¥å…·: {self.final_data['metadata']['categories']['tools']} ä¸ª")
        print(f"   ðŸ’¼ æœºä¼š: {self.final_data['metadata']['categories']['opportunities']} ä¸ª")

        return self.final_data

    def generate_summary_report(self):
        """ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š"""
        report_file = self.data_dir / "daily_summary.md"

        current_date = datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')

        report_content = f"""# çŽ¯å¢ƒç§‘å­¦æ¯æ—¥æ‘˜è¦æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {current_date} {datetime.datetime.now().strftime('%H:%M AEST')}

## ðŸ“Š æ•°æ®ç»Ÿè®¡
- çŽ¯å¢ƒç§‘å­¦æ–°é—»: {len(self.final_data['environmental_news'])} æ¡
- AIå·¥å…·æŽ¨è: {len(self.final_data['ai_tools'])} ä¸ª  
- å®žè·µæœºä¼š: {len(self.final_data['opportunities'])} ä¸ª
- æ€»è®¡: {self.final_data['metadata']['total_items']} æ¡è®°å½•

## ðŸŒ³ ä»Šæ—¥çŽ¯å¢ƒç§‘å­¦äº®ç‚¹
"""

        for i, news in enumerate(self.final_data['environmental_news'][:3], 1):
            report_content += f"""
### {i}. {news['title']}
- **æ¥æº**: {news['source']}
- **ç±»åˆ«**: {news['category']} 
- **ç´§æ€¥ç¨‹åº¦**: {news['urgency']}
- **æ‘˜è¦**: {news['description'][:150]}...
- **é“¾æŽ¥**: {news['link']}
"""

        report_content += f"""

## ðŸš€ æŽ¨èå·¥å…·äº®ç‚¹
"""

        for i, tool in enumerate(self.final_data['ai_tools'][:2], 1):
            report_content += f"""
### {i}. {tool['name']} ({tool['category']} - {tool['difficulty']})
- **åŠŸèƒ½**: {tool['summary']}
- **å®žç”¨æ€§**: {tool['usefulness'][:200]}...
- **é“¾æŽ¥**: {tool['link']}
"""

        report_content += f"""

## ðŸ’¼ çƒ­é—¨å®žè·µæœºä¼š
"""

        for i, opp in enumerate(self.final_data['opportunities'][:2], 1):
            report_content += f"""
### {i}. {opp['title']} ({opp['type']})
- **æœºæž„**: {opp['organization']}
- **åœ°ç‚¹**: {opp['location']}
- **æ‰¿è¯º**: {opp['commitment']}
- **è”ç³»**: {opp['contact']}
"""

        report_content += f"""

---
*æœ¬æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–ç³»ç»Ÿç”Ÿæˆ | ä¸‹æ¬¡æ›´æ–°: {self.final_data['metadata']['next_update']}*
*æ•°æ®æ¥æº: {', '.join(self.final_data['metadata']['data_sources'])}*
"""

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

        print(f"ðŸ“‹ æ¯æ—¥æ‘˜è¦æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

if __name__ == "__main__":
    processor = DashboardDataProcessor()
    processor.process_all_data()
    processor.generate_summary_report()
